{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c55be3d05968429198b46555da555096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c5252d72d0a4f5bb7ed507cf150a137",
              "IPY_MODEL_6983ce5527454ae0a5c101b551e29df1",
              "IPY_MODEL_a97bd3a63d7e4bb7b818ef06954f0cfe"
            ],
            "layout": "IPY_MODEL_8b6cf99ed6fd4de8b9a412c865523e5f"
          }
        },
        "3c5252d72d0a4f5bb7ed507cf150a137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_240b1a055e82420282cfda553b8e0d3b",
            "placeholder": "​",
            "style": "IPY_MODEL_945cb6bda3ba429fba5fd0d47e01928a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6983ce5527454ae0a5c101b551e29df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c565e198a8c4aba9358b3a9fb3a08b5",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_997a575b09404cb6b98225fef1eb4e9a",
            "value": 4
          }
        },
        "a97bd3a63d7e4bb7b818ef06954f0cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d55259184f1d4ffaa9205a3a19d77e55",
            "placeholder": "​",
            "style": "IPY_MODEL_5329390fe1344a1f80bced2831f9e3a7",
            "value": " 4/4 [01:27&lt;00:00, 18.70s/it]"
          }
        },
        "8b6cf99ed6fd4de8b9a412c865523e5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "240b1a055e82420282cfda553b8e0d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "945cb6bda3ba429fba5fd0d47e01928a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c565e198a8c4aba9358b3a9fb3a08b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "997a575b09404cb6b98225fef1eb4e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d55259184f1d4ffaa9205a3a19d77e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5329390fe1344a1f80bced2831f9e3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xuan1905/misc/blob/main/memorag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook demonstrates the usage of [MemoRAG](https://github.com/qhjqhj00/MemoRAG/tree/main), showcasing its capabilities for memory-augmented retrieval and generation.\n",
        "\n",
        "### Please install dependencies first."
      ],
      "metadata": {
        "id": "aXQT9sZ8hFr3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voqzQo7iBmCV"
      },
      "outputs": [],
      "source": [
        "!pip install memorag==0.1.3\n",
        "!pip install faiss-gpu # please install faiss using conda to obtain the latest version. Here using pip as example\n",
        "!pip install flash_attn\n",
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Downloading model files from HuggingFace may take a few minutes. Please be patient while the files are being downloaded."
      ],
      "metadata": {
        "id": "wwVcTfSEXYlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from memorag import MemoRAG\n",
        "\n",
        "pipe = MemoRAG(\n",
        "    mem_model_name_or_path=\"TommyChien/memorag-qwen2-7b-inst\",\n",
        "    ret_model_name_or_path=\"BAAI/bge-m3\",\n",
        "    beacon_ratio=16,\n",
        "    load_in_4bit=True,\n",
        "    enable_flash_attn=False # T4 GPU does not support flash attention\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "c55be3d05968429198b46555da555096",
            "3c5252d72d0a4f5bb7ed507cf150a137",
            "6983ce5527454ae0a5c101b551e29df1",
            "a97bd3a63d7e4bb7b818ef06954f0cfe",
            "8b6cf99ed6fd4de8b9a412c865523e5f",
            "240b1a055e82420282cfda553b8e0d3b",
            "945cb6bda3ba429fba5fd0d47e01928a",
            "2c565e198a8c4aba9358b3a9fb3a08b5",
            "997a575b09404cb6b98225fef1eb4e9a",
            "d55259184f1d4ffaa9205a3a19d77e55",
            "5329390fe1344a1f80bced2831f9e3a7"
          ]
        },
        "id": "NVtCmj7JByHr",
        "outputId": "7b3017a9-d578-4f0d-a8ec-e07affa6f3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-09-09 06:29:42,463] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c55be3d05968429198b46555da555096"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load example text or use your own data.\n",
        "### For this demonstration, we are using half of the book’s content to accommodate limited GPU memory. Feel free to experiment with your own data as well.\n",
        "\n"
      ],
      "metadata": {
        "id": "T3bQcPukXztR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import tiktoken\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/qhjqhj00/MemoRAG/main/examples/harry_potter.txt'\n",
        "response = requests.get(url)\n",
        "content = response.text\n",
        "\n",
        "print(f\"The raw database has {len(encoding.encode(content))} tokens...\")\n",
        "\n",
        "small_part = \" \".join(content.split()[:50000])\n",
        "print(f\"Using part of the database: with {len(encoding.encode(small_part))} tokens...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edI7hJu1SuAb",
        "outputId": "e9ae576e-a53a-49eb-88b7-1344f3075639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The raw database has 122591 tokens...\n",
            "Using part of the database: with 67574 tokens...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forming memory for a long context can be slow (a few minutes) when using the free T4 GPU. **You can skip this step** and use the next code block to download pre-cached memory instead."
      ],
      "metadata": {
        "id": "RlD4cs9KYFwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pipe.memorize(small_part, save_dir=\"content/harry_potter/\", print_stats=True)"
      ],
      "metadata": {
        "id": "UCmhnPmnJU7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The following codes download the pre-cached memory."
      ],
      "metadata": {
        "id": "-rBsucRRgZ10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "url = 'https://huggingface.co/datasets/TommyChien/MemoRAG-data/resolve/main/hp_qwen2.tar.bz2'\n",
        "\n",
        "download_path = '/content/hp_qwen2.tar.bz2'\n",
        "extract_path = '/content/'\n",
        "\n",
        "response = requests.get(url, stream=True)\n",
        "if response.status_code == 200:\n",
        "    with open(download_path, 'wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=1024):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "    print(f\"File downloaded successfully: {download_path}\")\n",
        "else:\n",
        "    print(f\"Failed to download file: {response.status_code}\")\n",
        "\n",
        "if os.path.exists(download_path):\n",
        "    with tarfile.open(download_path, 'r:bz2') as tar:\n",
        "        tar.extractall(path=extract_path)\n",
        "    print(f\"File extracted successfully to: {extract_path}\")\n",
        "else:\n",
        "    print(\"Downloaded file not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srDMqK3hdkvt",
        "outputId": "b3717328-ca24-4cc1-9576-4a30c3ba9e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully: /content/hp_qwen2.tar.bz2\n",
            "File extracted successfully to: /content/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The following codes load the downloaded pre-cached memory."
      ],
      "metadata": {
        "id": "RTm2UzR0gkqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "pipe.load(\"/content/harry_potter_qwen2_ratio16\", print_stats=True)\n",
        "print(f\"Loading from cache takes {round(time.time()-start,2)} for the full book.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQvnWJjaXNpt",
        "outputId": "0c331881-9311-4a64-e17b-8b7917c463a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/memorag/memorag.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.memory = torch.load(path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory file size: 0.24 GB\n",
            "Number of chunks in retrieval corpus: 136\n",
            "Loading from cache takes 2.54 for the full book.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In the following, we perform the QA task and retrieval task."
      ],
      "metadata": {
        "id": "jJiEdeIWg0tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perform QA task\n",
        "\n",
        "query = \"What's the theme of the book?\"\n",
        "\n",
        "res = pipe(context=small_part, query=query, task_type=\"qa\", max_new_tokens=256)\n",
        "print(f\"Using memory to produce the answer: \\n{res} \\n\\n\")\n",
        "res = pipe(context=small_part, query=query, task_type=\"memorag\", max_new_tokens=256)\n",
        "print(f\"Using MemoRAG to produce the answer: \\n{res[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjINBwzFScKn",
        "outputId": "c80a38de-fd18-49c0-baa7-1031c99e7051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using memory to produce the answer: \n",
            "The theme of the book is Harry Potter's adventures at Hogwarts School of Witchcraft and Wizardry, his friendship with Ron Weasley and Hermione Granger, and his battle against Lord Voldemort. \n",
            "\n",
            "\n",
            "Using MemoRAG to produce the answer: \n",
            "The theme of the book is the struggle between good and evil, represented by Harry Potter and Voldemort respectively, and the importance of friendship and loyalty in Hogwarts School of Witchcraft and Wizardry.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perform retrieval task\n",
        "\n",
        "clues = pipe.mem_model.rewrite(query).split(\"\\n\")\n",
        "clues = [q for q in clues if len(q.split()) > 3]  # Filter out short or irrelevant clues\n",
        "print(\"Clues generated from memory:\\n\", clues)\n",
        "\n",
        "# Retrieve relevant passages based on the recalled clues\n",
        "retrieved_passages = pipe._retrieve(clues)\n",
        "print(\"Retrieved passages:\")\n",
        "print(\"\\n======\\n\".join(retrieved_passages[:3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGTY7Ay3OonZ",
        "outputId": "dfec4a7d-174d-42e0-a57b-1906635383e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clues generated from memory:\n",
            " ['What magical events occur at Hogwarts School during the school year described in the book?', 'What challenges do Harry Potter and his friends face at Hogwarts School?', 'What significant magical artifacts are mentioned in the book?', 'What role does the Chamber of Secrets play in the story?', 'How does Harry Potter discover his ability to communicate with snakes?', \"What is the significance of Salazar Slytherin's legacy at Hogwarts?\", 'What is the relationship between Harry Potter and the Chamber of Secrets?', 'What is the impact of the Chamber of Secrets on the students at Hogwarts?', \"How does Harry Potter's past experiences influence his actions during the events described in the book?\"]\n",
            "Retrieved passages:\n",
            "For the first couple of weeks back, Harry had enjoyed muttering nonsense words under his breath and watching Dudley tearing out of the room as fast as his fat legs would carry him. But the long silence from Ron and Hermione had made Harry feel so cut off from the magical world that even taunting Dudley had lost its appeal - and now Ron and Hermione had forgotten his birthday. What wouldn't he give now for a message from Hogwarts? From any witch or wizard? He'd almost be glad of a sight of his archenemy, Draco Malfoy, just to be sure it hadn't all been a dream .... Not that his whole year at Hogwarts had been fun. At the very end of last term, Harry had come face-to-face with none other than Lord Voldemort himself. Voldemort might be a ruin of his former self, but he was still terrifying, still cunning, still determined to regain power. Harry had slipped through Voldemort's clutches for a second time, but it had been a narrow escape, and even now, weeks later, Harry kept waking in the night, drenched in cold sweat, wondering where Voldemort was now, remembering his livid face, his wide, mad eyes Harry suddenly sat bolt upright on the garden bench. He had been staring absent-mindedly into the hedge - and the hedge was staring back. Two enormous green eyes had appeared among the leaves. Harry jumped to his feet just as a jeering voice floated across the lawn. \"I know what day it is,\" sang Dudley, waddling toward him. The huge eyes blinked and vanished. \"What?\" said Harry, not taking his eyes off the spot where they had been. \"I know what day it is,\" Dudley repeated, coming right up to him. \"Well done,\" said Harry. \"So you've finally learned the days of the week.\" \"Today's your birthday,\" sneered Dudley. \"How come you haven't got any cards? Haven't you even got friends at that freak place?\" \"Better not let your mum hear you talking about my school,\" said Harry coolly. Dudley hitched up his trousers, which were slipping down his fat bottom. \"Why're you staring at the hedge?\" he said suspiciously. \" I , m trying to decide what would be the best spell to set it on fire,\" said Harry. Dudley stumbled backward at once, a look of panic on his fat face.\n",
            "======\n",
            "I don't belong here. I belong in your world - at Hogwarts.\" \"No, no, no,\" squeaked Dobby, shaking his head so hard his ears flapped. \"Harry Potter must stay where he is safe. He is too great, too good, to lose. If Harry Potter goes back to Hogwarts, he will be in mortal danger.\" \"Why?\" said Harry in surprise. \"There is a plot, Harry Potter. A plot to make most terrible things happen at Hogwarts School of Witchcraft and Wizardry this year,\" whispered Dobby, suddenly trembling all over. \"Dobby has known it for months, sir. Harry Potter must not put himself in peril. He is too important, sir!\" \"What terrible things?\" said Harry at once. \"Who's plotting them?\" Dobby made a funny choking noise and then banged his head frantically against the wall. \"All right!\" cried Harry, grabbing the elf's arm to stop him. \"You can't tell me. I understand. But why are you warning me?\" A sudden, unpleasant thought struck him. \"Hang on - this hasn't got anything to do with Vol- - sorry - with You-Know-Who, has it? You could just shake or nod,\" he added hastily as Dobby's head tilted worryingly close to the wall again. Slowly, Dobby shook his head. \"Not -not He- Who-Must-Not-Be-Named, sir =' But Dobby's eyes were wide and he seemed to be trying to give Harry a hint. Harry, however, was completely lost. \"He hasn't got a brother, has he?\" Dobby shook his head, his eyes wider than ever. \"Well then, I can't think who else would have a chance of making horrible things happen at Hogwarts,\" said Harry. \"I mean, there's Dumbledore, for one thing - you know who Dumbledore is, don't you?\" Dobby bowed his head. \"Albus Dumbledore is the greatest headmaster Hogwarts has ever had. Dobby knows it, sir. Dobby has heard Dumbledore's powers rival those of He-Who-Must-Not-Be-Named at the height of his strength. But, sir\" - Dobby's voice dropped to an urgent whisper - \"there are powers Dumbledore doesn't ... powers no decent wizard. . .\"\n",
            "======\n",
            "Mason's head, and swooped out again. Mrs. Mason screamed like a banshee and ran from the house shouting about lunatics. Mr. Mason stayed just long enough to tell the Dursleys that his wife was mortally afraid of birds of all shapes and sizes, and to ask whether this was their idea of a joke. Harry stood in the kitchen, clutching the mop for support, as Uncle Vernon advanced on him, a demonic glint in his tiny eyes. \"Read it!\" he hissed evilly, brandishing the letter the owl had delivered. \"Go on - read it!\" Harry took it. It did not contain birthday greetings. Dear Mr. Potter, We have received intelligence that a Hover Charm was used at your place of residence this evening at twelve minutes past nine. As you know, underage wizards are not permitted to perform spells outside school, and further spellwork on your part may lead to expulsion from said school (Decree for the Reasonable Restriction of Underage Sorcery, 1875, Paragraph C). We would also ask you to remember that any magical activity that risks notice by members of the non-magical community (Muggles) is a serious offense under section 13 of the International Confederation of Warlocks' Statute of Secrecy. Enjoy your holidays! Yours sincerely, Mafalda Hopkirk IMPROPER USE OF MAGIC OFFICE Ministry of Magic Harry looked up from the letter and gulped. \"You didn't tell us you weren't allowed to use magic outside school,\" said Uncle Vernon, a mad gleam dancing in his eyes. \"For got to mention it .... Slipped your mind, I daresay ..... He was bearing down on Harry like a great bulldog, all his teeth bared. \"Well, I've got news for you, boy . ... I'm locking you up .... You're never going back to that school ... never ... and if you try and magic yourself out - they'll expel you!\" And laughing like a maniac, he dragged Harry back upstairs. Uncle Vernon was as bad as his word. The following morning, he paid a man to fit bars on Harry's window. He himself fitted a cat- flap in the bedroom door, so that small amounts of food could be pushed inside three times a day. They let Harry out to use the bathroom morning and evening. Otherwise, he was locked in his room around the clock.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "INdW4mH5c3D2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}